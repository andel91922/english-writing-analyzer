import streamlit as st
import requests

# ğŸ” éŒ¯èª¤åµæ¸¬åŠŸèƒ½ï¼ˆé€é LanguageTool APIï¼‰
def analyze_text(text):
    url = "https://api.languagetoolplus.com/v2/check"
    params = {
        "text": text,
        "language": "en-US"
    }

    response = requests.post(url, data=params)
    matches = response.json().get("matches", [])

    errors = []
    for match in matches:
        error = text[match["offset"]: match["offset"] + match["length"]]
        message = match["message"]
        replacements = match.get("replacements", [])
        rule_type = match["rule"]["issueType"]
        errors.append({
            "error": error,
            "suggestion": replacements[0]["value"] if replacements else "ç„¡",
            "explanation": message,
            "type": rule_type
        })
    return errors

# ç²—ç•¥ä¼°è¨ˆ CEFR ç­‰ç´š
def estimate_cefr_level(text, num_errors):
    words = text.split()
    word_count = len(words)

    if word_count < 5 or len(text.strip()) < 20:
        return "å…§å®¹ä¸è¶³ï¼Œç„¡æ³•è©•ä¼°ç¨‹åº¦"

    # è©•åˆ†é‚è¼¯
    if error_ratio > 0.15 or avg_sentence_length < 8:
        return "A1~A2"
    elif error_ratio > 0.08 or avg_sentence_length < 12:
        return "B1"
    elif error_ratio > 0.03 or num_connectors < 3:
        return "B2"
    else:
        return "C1"

# ğŸ“Š ç•«åœ–ç”¨çš„å‡½å¼
def plot_error_distribution(error_dict):
    fig, ax = plt.subplots()
    types = list(error_dict.keys())
    counts = list(error_dict.values())
    ax.bar(types, counts, color="pink")
    ax.set_title("ğŸ“ˆ éŒ¯èª¤åˆ†ä½ˆåœ–è¡¨")
    ax.set_ylabel("å‡ºç¾æ¬¡æ•¸")
    ax.set_xticklabels(types, rotation=0)
    st.pyplot(fig)

# Streamlit ä»‹é¢é–‹å§‹
st.set_page_config(page_title="LingoScope è‹±æ–‡å¯«ä½œè¨ºæ–·å·¥å…·")
st.title("ğŸ“˜ LingoScope è‹±æ–‡å¯«ä½œè¨ºæ–·å·¥å…·")
st.write("è¼¸å…¥ä¸€æ®µè‹±æ–‡å¯«ä½œï¼Œæˆ‘å€‘æœƒå¹«ä½ åˆ†ææ–‡æ³•éŒ¯èª¤èˆ‡ç¨‹åº¦åˆ¤æ–·ã€‚")

text_input = st.text_area("ğŸ“ è«‹è¼¸å…¥ä½ çš„è‹±æ–‡ä½œæ–‡", height=200)

if st.button("ğŸ” åˆ†ææˆ‘çš„å¯«ä½œ"):
    if not text_input.strip():
        st.warning("è«‹å…ˆè¼¸å…¥è‹±æ–‡å…§å®¹ï¼")
    else:
        with st.spinner("åˆ†æä¸­ï¼Œè«‹ç¨å€™..."):
            errors = analyze_text(text_input)
            level = estimate_cefr_level(text_input, len(errors))

        st.subheader("ğŸ” åˆ†æçµæœ")
        if not errors:
            st.success("æ­å–œä½ ï¼Œæœªæª¢æ¸¬åˆ°æ˜é¡¯éŒ¯èª¤ï¼ğŸ‰")
        else:
            for i, e in enumerate(errors, 1):
                st.markdown(f"""
                **éŒ¯èª¤ {i}**
                - âŒ éŒ¯èª¤éƒ¨åˆ†ï¼š`{e['error']}`
                - ğŸ›  å»ºè­°ï¼š{e['suggestion']}
                - ğŸ“– èªªæ˜ï¼š{e['explanation']}
                - ğŸ§  éŒ¯èª¤é¡å‹ï¼š{e['type']}
                """)

            # çµ±è¨ˆéŒ¯èª¤é¡å‹
            type_count = {}
            for e in errors:
                t = e["type"]
                type_count[t] = type_count.get(t, 0) + 1

            st.subheader("ğŸ“Š éŒ¯èª¤çµ±è¨ˆ")
            for t, c in type_count.items():
                st.write(f"- `{t}`ï¼š{c} ç­†")

            plot_error_distribution(type_count)

        st.subheader("ğŸ§  æ¨ä¼°è‹±æ–‡ç¨‹åº¦")
        if level == "å…§å®¹ä¸è¶³ï¼Œç„¡æ³•è©•ä¼°ç¨‹åº¦":
            st.warning("âš ï¸ æ–‡å­—å¤ªçŸ­æˆ–ä¸å…·èªè¨€å…§å®¹ï¼Œç„¡æ³•æ¨ä¼°è‹±æ–‡ç¨‹åº¦")
        else:
            st.success(f"ä½ çš„è‹±æ–‡ç¨‹åº¦å¤§ç´„ç‚ºï¼š**{level}**")
        
